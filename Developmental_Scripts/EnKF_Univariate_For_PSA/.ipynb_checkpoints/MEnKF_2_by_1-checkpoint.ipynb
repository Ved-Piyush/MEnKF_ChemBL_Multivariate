{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "348e4cc8-b5ed-4de2-94ac-04864aed2c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 09:02:32.309565: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-06-06 09:02:32.311888: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 09:02:32.352417: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-06-06 09:02:32.353255: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-06 09:02:33.360401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import random\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d651b4b9-1e82-4a9d-9bd1-cb81dfc6dcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "alogp_bottleneck = np.load(\"..//Data/small_mol_phase_3_features_for_both.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4127940b-c228-4758-bf25-9377f4c3cc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = pd.read_csv(\"..//Data/smiles_with_rdkit_with_small_phase_3_outputs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e60734e-1c26-44b4-8947-a8f593b4987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/statgrads/vpiyush2/.conda/envs/enkf/lib/python3.11/site-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 1.1.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "std_targets = pickle.load( open('..//Data//target_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a63d2670-c260-42ed-97cd-1b933842dee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = std_targets.transform(y_valid.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9eff71a-123a-4671-90d2-9353981381aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94fe0f13-f79e-4bc0-8a5a-024377bf615d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac169765-fc20-4c6b-9dd7-ba40a2368da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.03295671, 1.57935602])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.var(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51e62922-6255-43bc-b4e1-717b84c13a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.42581791, 1.25672432])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(((targets_train - targets_train.mean(0))**2).mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c00c61d-66c7-4c66-8517-c5fa9a90e572",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_train = alogp_bottleneck[:, :32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0596c8-4d55-4c2e-bd58-f33bf1a082c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d895e852-cffc-4e91-aa98-34fbef6fd1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2vec_train = alogp_bottleneck[:, 32:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "622df577-2391-443f-95fe-9bc0b13972a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ann(hidden = 32, input_shape = 256, output_shape = 2): \n",
    "    input_layer = tf.keras.layers.Input(shape = (input_shape))\n",
    "    hidden_layer = tf.keras.layers.Dense(hidden)\n",
    "    hidden_output = hidden_layer(input_layer)\n",
    "    pred_layer = tf.keras.layers.Dense(output_shape, activation = \"relu\")\n",
    "    pred_output = pred_layer(hidden_output)\n",
    "#     pred_output = tf.keras.layers.Activation(\"softmax\")(pred_output)\n",
    "    model = tf.keras.models.Model(input_layer, pred_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3af0e377-dee7-4cb8-8f5e-01966b6161eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1, h2 = 16, 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b301888-fed4-4809-b75f-2d9f036ea940",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-06 09:02:34.755108: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-06-06 09:02:34.755141: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:168] retrieving CUDA diagnostic information for host: c3101.swan.hcc.unl.edu\n",
      "2023-06-06 09:02:34.755148: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:175] hostname: c3101.swan.hcc.unl.edu\n",
      "2023-06-06 09:02:34.755237: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:199] libcuda reported version is: 525.85.5\n",
      "2023-06-06 09:02:34.755255: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:203] kernel reported version is: 525.85.5\n",
      "2023-06-06 09:02:34.755260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:309] kernel version seems to match DSO: 525.85.5\n"
     ]
    }
   ],
   "source": [
    "ann_15 = ann(h1, 32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3050ec42-3c44-44ba-a06b-5b70010de582",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_20 = ann(h2, 32, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "680f4495-16c6-4906-a8ba-712feba95a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 = ann_15.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a4a8564-9ad7-4d1f-aaa5-fd31948ffc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_2 = ann_20.count_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7923abcc-671c-41b1-a75c-fdfc13a1d365",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights = total_weights_1 + total_weights_2 + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe1315fb-cf6c-424f-bb36-ca52a97e94b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b7a57f-49a7-4ab8-9ca3-ebeded21fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.40047573e-03,  3.83895560e-01,  2.24939275e-01, ...,\n",
       "        -2.19649480e+00,  2.62517918e+00, -5.48647979e-01],\n",
       "       [-3.21179953e-01, -2.84568313e-01, -1.20750605e+00, ...,\n",
       "         2.49544534e-01, -5.07482222e-01,  1.17155539e+00]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3a16e864-7052-4a50-922b-ac56a5682f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6c2355d-1954-4693-a122-9e0ab3b7dc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.6987741563528856"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance(targets_train[:,0], targets_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "324b286d-9192-491f-9862-7a0c72479aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t_small_train = np.cov(targets_train.T)\n",
    "# R_t_small_resid = np.cov(resids.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f13b504-6901-4d7d-94dd-bbb5bdf145d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0350788 , -0.69877416],\n",
       "       [-0.69877416,  1.58100462]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_t_small_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f259e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lambda_val = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86f56887-e5c6-475c-9faa-abb5938f606d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc782b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0350788 , -0.69877416],\n",
       "       [-0.69877416,  1.58100462]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_t_small_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6396a7c5-2d2c-4e58-a07d-826d286fe5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t_small_train = [[R_t_small_train[0,0], 0, R_t_small_train[0,1], 0],\n",
    "                   [0, R_t_small_train[0,0], 0, R_t_small_train[1,0]], \n",
    "                  [R_t_small_train[0,1], 0, R_t_small_train[1,1],0], \n",
    "                  [0, R_t_small_train[0,1], 0, R_t_small_train[1,1]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "113335f9-5743-4c07-8a1a-968886ad1687",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_t_small_train = np.array(R_t_small_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7dec3d08-d1b7-4e6c-bf46-50bc7c399bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.0350788 ,  0.        , -0.69877416,  0.        ],\n",
       "       [ 0.        ,  2.0350788 ,  0.        , -0.69877416],\n",
       "       [-0.69877416,  0.        ,  1.58100462,  0.        ],\n",
       "       [ 0.        , -0.69877416,  0.        ,  1.58100462]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_t_small_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0e4f4209-efba-45ae-98d8-d6d7962e52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = R_t_small_train[0,0]\n",
    "cov = R_t_small_train[0,1]\n",
    "var2 = R_t_small_train[1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b9e8a8a-33b7-4b41-8145-42ec13343c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3395c83f-86d3-4c82-a3dd-fecae769ae83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3cbc337-4ad3-4193-88b7-59ff739d5fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal as mvn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09e9c75b-a4e2-49bd-bb7e-52707dd514f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f58f94b0-4868-4d24-91a4-9ab6cf5acf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "047a758e-01f0-4fd1-a8b6-348e21ad0a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "#     e_x = np.exp(x - np.max(x))\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7603886f-4774-4af0-8a6b-3db53d31bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ead1031-79b5-483d-91f7-cf0e0a37cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e0b9926-9792-45cc-8ee1-c3b96bb18b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets_with_weights(batch_data, batch_data1, initial_ensembles, size_ens): \n",
    "\n",
    "    weights_ann_1 = ann_15.get_weights()\n",
    "    weights_ann_2 = ann_20.get_weights()\n",
    "    \n",
    "    n_hidden_1 = len(weights_ann_1[0].ravel())\n",
    "    \n",
    "    hidden_weights_1 = initial_ensembles[:,:n_hidden_1].reshape( size_ens, batch_data.shape[1], h1)\n",
    "    \n",
    "    \n",
    "    hidden_output_1 = np.einsum('ij,kjl->kil', batch_data, hidden_weights_1)\n",
    "\n",
    "    \n",
    "    hidden_layer_bias_1 = initial_ensembles[:,n_hidden_1:(n_hidden_1 + h1)].reshape(size_ens, 1,  h1)\n",
    "\n",
    "\n",
    "    hidden_output_1 = hidden_output_1 + hidden_layer_bias_1\n",
    "\n",
    "    n_pred_weights_1 = len(weights_ann_1[2].ravel())\n",
    "\n",
    "    output_weights_1 = initial_ensembles[:,(n_hidden_1 + h1):(n_hidden_1 + h1 + n_pred_weights_1) ].reshape(size_ens, h1, target_dim)\n",
    "\n",
    "\n",
    "    output_1 = np.einsum('ijk,ikl->ijl', hidden_output_1, output_weights_1)\n",
    "\n",
    "\n",
    "    output_layer_bias_1 = initial_ensembles[:,(n_hidden_1 + h1 + n_pred_weights_1):(n_hidden_1 + h1 + n_pred_weights_1 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "\n",
    "    final_output_1 = output_1 + output_layer_bias_1\n",
    "\n",
    "\n",
    "\n",
    "    n_hidden_2 = len(weights_ann_2[0].ravel())\n",
    "\n",
    "    initial_ensembles_1 = initial_ensembles.copy()[:, total_weights_1:(total_weights_1+ total_weights_2)]\n",
    "\n",
    "    hidden_weights_2 = initial_ensembles_1[:,:n_hidden_2].reshape(size_ens, batch_data1.shape[1], h2)\n",
    "\n",
    "\n",
    "\n",
    "    hidden_output_2 = np.einsum('ij,kjl->kil', batch_data1, hidden_weights_2)\n",
    "\n",
    "    hidden_layer_bias_2 = initial_ensembles_1[:,n_hidden_2:(n_hidden_2 + h2)].reshape(size_ens, 1,  h2)\n",
    "\n",
    "\n",
    "    # hidden_layer_bias_2 = np.expand_dims(hidden_layer_bias_2, 0)\n",
    "\n",
    "    hidden_output_2 = hidden_output_2+ hidden_layer_bias_2\n",
    "#     hidden_layer_bias_2 = hidden_layer_bias_2 + hidden_layer_bias_2\n",
    "\n",
    "\n",
    "    n_pred_weights_2 = len(weights_ann_2[2].ravel())\n",
    "\n",
    "    output_weights_2 = initial_ensembles_1[:,(n_hidden_2 + h2):(n_hidden_2 + h2 + n_pred_weights_2) ].reshape(size_ens, h2, target_dim)\n",
    "\n",
    "\n",
    "    output_2 = np.einsum('ijk,ikl->ijl', hidden_output_2, output_weights_2)\n",
    "\n",
    "\n",
    "    output_layer_bias_2 = initial_ensembles_1[:,(n_hidden_2 + h2 + n_pred_weights_2):(n_hidden_2 + h2 + n_pred_weights_2 + target_dim)].reshape(size_ens, 1, target_dim)\n",
    "\n",
    "    # output_layer_bias_2 = np.expand_dims(output_layer_bias_2, 0)\n",
    "\n",
    "\n",
    "    final_output_2 = output_2 + output_layer_bias_2\n",
    "\n",
    "\n",
    "    weights_1 = initial_ensembles[:, :total_weights_1]\n",
    "\n",
    "    weights_2 = initial_ensembles[:, total_weights_1:(total_weights_1 + total_weights_2)]\n",
    "\n",
    "#     print(weights_1.shape)\n",
    "    \n",
    "    # print(weights_2.shape)\n",
    "\n",
    "    avg_weights = initial_ensembles[:, -1].reshape(-1,1)\n",
    "    \n",
    "    # avg_weights_not_sig = avg_weights.reshape(avg_weights.shape[0], 1, avg_weights.shape[1])\n",
    "    \n",
    "    \n",
    "    avg_weights_sig = expit(avg_weights)\n",
    "    \n",
    "    avg_weights_sig = avg_weights_sig.reshape(avg_weights_sig.shape[0], 1, avg_weights_sig.shape[1])\n",
    "    \n",
    "    \n",
    "    complement_weights_sig = 1 - expit(avg_weights)\n",
    "    \n",
    "    complement_weights_sig = complement_weights_sig.reshape(complement_weights_sig.shape[0], 1, complement_weights_sig.shape[1])\n",
    "    \n",
    "\n",
    "    final_output_1 = final_output_1*complement_weights_sig\n",
    "    \n",
    "    final_output_2 = final_output_2*avg_weights_sig\n",
    "    \n",
    "    final_output_1 = final_output_1.reshape(final_output_1.shape[0], final_output_1.shape[1]*final_output_1.shape[2])\n",
    "    \n",
    "    final_output_2 = final_output_2.reshape(final_output_2.shape[0], final_output_2.shape[1]*final_output_2.shape[2])\n",
    "\n",
    "    weights_1_add = np.zeros((size_ens, (total_weights_2 - total_weights_1)))\n",
    "\n",
    "\n",
    "\n",
    "    weights_1 = np.hstack((weights_1, weights_1_add))\n",
    "    \n",
    "    stack_1 = np.concatenate((final_output_1, weights_1 , np.zeros((size_ens,1))), axis = 1)\n",
    "\n",
    "    stack_2 = np.concatenate((final_output_2, weights_2 , avg_weights), axis = 1)\n",
    "    \n",
    "    initial_aug_state = np.hstack((stack_1, stack_2))\n",
    "    \n",
    "    return initial_aug_state, final_output_1, final_output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da529e45-3398-4b0d-95ef-3b146863052f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import block_diag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d6f3896-2a46-4572-9a7b-2234c43a7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a273523f-d5ac-41d4-b233-8d4895b6b7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8508b88-1842-434c-8af2-79661d0b2e69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1125"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bcd78078-1b79-4e97-b3d6-3ee57124158f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_weights//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "182dc784-3e29-4aef-99ec-3b8f172c8738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b300c05b-023f-497f-8a05-97da2921eb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(959, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "618ba17e-8ffe-4797-8352-2f081258c71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_one(idx, batch_size = 32, var_weights = 0.5, reduction = 4,inflation_factor = 0.01, \n",
    "           R_t_small = R_t_small_train, fudge = 1): \n",
    "    \n",
    "    size_ens = int(total_weights//reduction)\n",
    "    for_convex = beta(a = 1, b = 1).rvs(size_ens)\n",
    "#     print(for_convex.mean())\n",
    "    for_convex = np.log(for_convex/(1-for_convex)).reshape(-1,1)\n",
    "    \n",
    "    X_train_logits = targets_train\n",
    "    train_idx = list(range(0, X_train_logits.shape[0]))\n",
    "    batch_chunks = [train_idx[i:i+batch_size] for i in range(0,len(train_idx),batch_size)]\n",
    "\n",
    "    ## generate some augmented variable for iteration 0\n",
    "    initial_aug_state_mean = np.zeros((total_weights-1,))\n",
    "    initial_aug_state_mean = initial_aug_state_mean.reshape(-1,1)\n",
    "\n",
    "    initial_aug_state_cov = var_weights*np.identity((total_weights-1))\n",
    "    \n",
    "\n",
    "    initial_ensembles = mvn(initial_aug_state_mean.reshape(initial_aug_state_mean.shape[0],), initial_aug_state_cov).rvs(size = size_ens)\n",
    "\n",
    "    initial_ensembles = np.hstack((initial_ensembles,for_convex))\n",
    "\n",
    "    train_lstm = images_train\n",
    "\n",
    "    train_doc2vec = doc2vec_train\n",
    "\n",
    "    train_valid_lstm = train_lstm\n",
    "    train_valid_doc2vec = train_doc2vec\n",
    "    \n",
    "    for iter1 in tqdm(range(0,40)):\n",
    "        \n",
    "        batch_chunks = random.sample(batch_chunks, len(batch_chunks))\n",
    "\n",
    "        for batch_idx in tqdm(batch_chunks):\n",
    "\n",
    "            batch_data = train_valid_lstm[batch_idx,:]\n",
    "            batch_data1 = train_valid_doc2vec[batch_idx,:]\n",
    "\n",
    "            batch_targets = X_train_logits[batch_idx,:]\n",
    "            batch_targets = batch_targets.T.ravel()\n",
    "            \n",
    "            column_mod_2_shape = total_weights_2 + batch_targets.shape[0]*1 + 1\n",
    "        \n",
    "            H_t = np.hstack((np.identity(batch_targets.shape[0]), np.zeros((batch_targets.shape[0], column_mod_2_shape-batch_targets.shape[0]))))\n",
    "            \n",
    "            current_aug_state, column_mod_1, column_mod_2 = get_targets_with_weights(batch_data, batch_data1, initial_ensembles, size_ens)\n",
    "\n",
    "            current_aug_state = current_aug_state.reshape(current_aug_state.shape[0], current_aug_state.shape[1])\n",
    "\n",
    "            current_aug_state_var = np.cov(current_aug_state.T)\n",
    "\n",
    "            G_t = np.array([[1 , 1]]).T\n",
    "            \n",
    "            scirpt_H_t = np.kron(G_t.T, H_t)\n",
    "            \n",
    "            # print(\"scirpt_H_t\",scirpt_H_t.shape)\n",
    "            \n",
    "            temp1 = current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            temp2 = scirpt_H_t@current_aug_state_var@scirpt_H_t.T\n",
    "            \n",
    "            # print(batch_data.shape[0])\n",
    "            \n",
    "            n = batch_data.shape[0]\n",
    "            \n",
    "            ul = var1*np.identity(n)\n",
    "            \n",
    "            ur = cov*np.identity(n)\n",
    "            \n",
    "            ll = ul\n",
    "            \n",
    "            lr = var2*np.identity(n)\n",
    "            \n",
    "            upp = np.hstack((ul, ur))\n",
    "            \n",
    "            loww = np.hstack((ll, lr))\n",
    "            \n",
    "            R_t = np.vstack((upp, loww))\n",
    "            \n",
    "            # R_t = block_diag(*([R_t_small] * n))\n",
    "            \n",
    "            K_t = temp1@np.linalg.inv(temp2 + R_t) \n",
    "        \n",
    "            for ensemble_idx in range(0, current_aug_state.shape[0]):\n",
    "    \n",
    "            \n",
    "                measurement_error =  mvn(np.repeat(0,n*2), R_t, allow_singular = True).rvs(1).ravel().reshape(-1,1)\n",
    "    \n",
    "                target_current = batch_targets.ravel().reshape(-1,1) + measurement_error\n",
    "                \n",
    "                \n",
    "\n",
    "                current_aug_state[ensemble_idx,:] = current_aug_state[ensemble_idx,:] +(K_t@(target_current -scirpt_H_t@current_aug_state[ensemble_idx,:].reshape(-1,1))).reshape(current_aug_state.shape[1],)\n",
    "    \n",
    "\n",
    "            weights_ann_1 = current_aug_state[:, batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]\n",
    "            \n",
    "            weights_ann_2 = current_aug_state[:, (batch_targets.shape[0] + total_weights_1 + 1): (batch_targets.shape[0] + total_weights_1 + 1 + total_weights_2 )]  \n",
    "            \n",
    "            convex_weights = current_aug_state[:, -1].reshape(-1,1)\n",
    "            \n",
    "            avg_betas = expit(convex_weights)\n",
    "            \n",
    "            # print(np.mean(avg_betas))\n",
    "        \n",
    "            complement = 1-avg_betas\n",
    "            \n",
    "#             print(weights_ann_1.shape, weights_ann_2.shape, convex_weights.shape)\n",
    "            \n",
    "            \n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, convex_weights))\n",
    "            \n",
    "            initial_ensembles_mean = initial_ensembles.mean(0)\n",
    "            \n",
    "            initial_ensembles_cov = np.cov(initial_ensembles.T) +fudge*np.identity(initial_ensembles.shape[1])\n",
    "            \n",
    "            # print(initial_ensembles_cov.shape)\n",
    "            \n",
    "            initial_ensembles = mvn(initial_ensembles_mean.reshape(initial_ensembles_mean.shape[0],), initial_ensembles_cov, allow_singular=True).rvs(size = size_ens)\n",
    "            \n",
    "            weights_ann_1 = current_aug_state[:, batch_targets.shape[0]:(batch_targets.shape[0] + total_weights_1)]\n",
    "            \n",
    "            weights_ann_2 = current_aug_state[:, (batch_targets.shape[0] + total_weights_1 + 1): (batch_targets.shape[0] + total_weights_1 + 1 + total_weights_2 )]  \n",
    "            \n",
    "            convex_weights = current_aug_state[:, -1].reshape(-1,1)    \n",
    "            \n",
    "            initial_ensembles = np.hstack((weights_ann_1, weights_ann_2, convex_weights))\n",
    "            \n",
    "#             print(initial_ensembles.shape)\n",
    "            \n",
    "            current_aug_state1, column_mod_11, column_mod_21 = get_targets_with_weights(train_lstm, train_doc2vec, initial_ensembles, size_ens)\n",
    "            \n",
    "            initial_targets = column_mod_11 + column_mod_21\n",
    "            \n",
    "            initial_targets = initial_targets.reshape(initial_targets.shape[0], train_lstm.shape[0], target_dim)\n",
    "            \n",
    "            li = np.percentile(initial_targets, axis = 0, q = (2.5, 97.5))[0,:,:]\n",
    "            \n",
    "            ui = np.percentile(initial_targets, axis = 0, q = (2.5, 97.5))[1,:,:]\n",
    "            \n",
    "            width = ui - li\n",
    "            \n",
    "            avg_width_train = width.ravel().mean()\n",
    "            \n",
    "            # interim = expit(np.vstack((catch_train_logits[idx] , catch_valid_logits[idx] )))\n",
    "            \n",
    "            \n",
    "            ind = (targets_train >= li) & (targets_train <= ui)\n",
    "            \n",
    "            coverage_train= ind.ravel().mean()\n",
    "            \n",
    "            preds_train = initial_targets.mean(0)\n",
    "            \n",
    "            truth = targets_train\n",
    "            \n",
    "            preds= preds_train\n",
    "            \n",
    "        \n",
    "            rmse = np.sqrt(((truth - preds)**2).mean(0))\n",
    "\n",
    "            print(\"RMSE is \" + str(rmse))\n",
    "            # print(\"RMSE over is \" + str(rmse_over))\n",
    "            print(\"coverage_train is \" + str(coverage_train))\n",
    "            print(\"avg_width_train is \" + str(avg_width_train))            \n",
    "            \n",
    "\n",
    "    return truth, preds, rmse_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6bd79f76-6605-4316-847b-c8b5c5769ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359b4e38de1d41a08d6148f8cbe5ecc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a75798d0a6141ec94dc7792bff56a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is [6.7180513  2.03337489]\n",
      "coverage_train is 1.0\n",
      "avg_width_train is 41.603021797920285\n",
      "RMSE is [3.9576351  4.34860565]\n",
      "coverage_train is 1.0\n",
      "avg_width_train is 37.506509430721934\n",
      "RMSE is [4.89589145 2.48343272]\n",
      "coverage_train is 1.0\n",
      "avg_width_train is 28.564117517180712\n",
      "RMSE is [5.26430728 1.74679688]\n",
      "coverage_train is 1.0\n",
      "avg_width_train is 23.252951324812557\n",
      "RMSE is [1.7368109  1.64433673]\n",
      "coverage_train is 1.0\n",
      "avg_width_train is 14.086913382989428\n",
      "RMSE is [2.19352611 3.63985987]\n",
      "coverage_train is 0.9994786235662148\n",
      "avg_width_train is 9.294204931999099\n",
      "RMSE is [2.05161834 1.5761133 ]\n",
      "coverage_train is 0.9442127215849844\n",
      "avg_width_train is 5.324823032979305\n",
      "RMSE is [1.66232204 1.51034118]\n",
      "coverage_train is 0.9327424400417101\n",
      "avg_width_train is 4.928649702215528\n",
      "RMSE is [7.45328447 3.99840239]\n",
      "coverage_train is 0.9807090719499478\n",
      "avg_width_train is 10.439386465454076\n",
      "RMSE is [2.05903707 2.8278507 ]\n",
      "coverage_train is 0.913451511991658\n",
      "avg_width_train is 4.54858320807223\n",
      "RMSE is [2.9318284  1.54955695]\n",
      "coverage_train is 0.8915537017726799\n",
      "avg_width_train is 4.452525061173108\n",
      "RMSE is [1.35456946 1.5453076 ]\n",
      "coverage_train is 0.837851929092805\n",
      "avg_width_train is 3.4958410727578126\n",
      "RMSE is [1.63567816 1.41979266]\n",
      "coverage_train is 0.6590198123044838\n",
      "avg_width_train is 2.610475643275285\n",
      "RMSE is [1.65943481 1.24898724]\n",
      "coverage_train is 0.6548488008342023\n",
      "avg_width_train is 2.1845622726047145\n",
      "RMSE is [1.53451778 1.33109169]\n",
      "coverage_train is 0.5531803962460897\n",
      "avg_width_train is 1.8308214227352193\n",
      "RMSE is [1.74273165 1.34572777]\n",
      "coverage_train is 0.5\n",
      "avg_width_train is 1.563697307943155\n",
      "RMSE is [1.45358395 1.29809016]\n",
      "coverage_train is 0.454118873826903\n",
      "avg_width_train is 1.3631322035967524\n",
      "RMSE is [1.53239594 1.36063955]\n",
      "coverage_train is 0.44629822732012514\n",
      "avg_width_train is 1.4236567611015183\n",
      "RMSE is [1.48313964 1.27904674]\n",
      "coverage_train is 0.41605839416058393\n",
      "avg_width_train is 1.1504371435587049\n",
      "RMSE is [1.5131419  1.27746339]\n",
      "coverage_train is 0.4426485922836288\n",
      "avg_width_train is 1.2553992948995218\n",
      "RMSE is [1.48004003 1.29528439]\n",
      "coverage_train is 0.4337851929092805\n",
      "avg_width_train is 1.197560555069156\n",
      "RMSE is [1.50808066 1.28173128]\n",
      "coverage_train is 0.38894681960375393\n",
      "avg_width_train is 1.0752775479557768\n",
      "RMSE is [1.56690456 1.25972607]\n",
      "coverage_train is 0.40250260688216893\n",
      "avg_width_train is 1.1291881787235383\n",
      "RMSE is [1.57050264 1.25901886]\n",
      "coverage_train is 0.3905109489051095\n",
      "avg_width_train is 1.0875643254308136\n",
      "RMSE is [1.57364381 1.25472845]\n",
      "coverage_train is 0.34410844629822734\n",
      "avg_width_train is 0.9953477821932445\n",
      "RMSE is [1.57503289 1.25763092]\n",
      "coverage_train is 0.36339937434827946\n",
      "avg_width_train is 1.0219463555105146\n",
      "RMSE is [1.55708232 1.25542294]\n",
      "coverage_train is 0.32064650677789364\n",
      "avg_width_train is 0.8935820981765419\n",
      "RMSE is [1.55188567 1.25851631]\n",
      "coverage_train is 0.3284671532846715\n",
      "avg_width_train is 0.9080287395970629\n",
      "RMSE is [1.55552354 1.25696106]\n",
      "coverage_train is 0.3086548488008342\n",
      "avg_width_train is 0.8642848609819539\n",
      "RMSE is [1.55774506 1.25685282]\n",
      "coverage_train is 0.3091762252346194\n",
      "avg_width_train is 0.8572160401606497\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a6bc71a8796417b933e305167ce5aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE is [1.55455265 1.25696461]\n",
      "coverage_train is 0.3034410844629823\n",
      "avg_width_train is 0.8337787229427032\n",
      "RMSE is [1.55673596 1.25694746]\n",
      "coverage_train is 0.29509906152241916\n",
      "avg_width_train is 0.8014006114600224\n",
      "RMSE is [1.56089878 1.25703584]\n",
      "coverage_train is 0.28102189781021897\n",
      "avg_width_train is 0.7712328039276429\n",
      "RMSE is [1.56067176 1.25696817]\n",
      "coverage_train is 0.2789363920750782\n",
      "avg_width_train is 0.7567750137676231\n",
      "RMSE is [1.56219512 1.25697161]\n",
      "coverage_train is 0.27476538060479666\n",
      "avg_width_train is 0.7479307091387353\n",
      "RMSE is [1.56002993 1.25690896]\n",
      "coverage_train is 0.26850886339937435\n",
      "avg_width_train is 0.7293816037689307\n",
      "RMSE is [1.55919365 1.25691241]\n",
      "coverage_train is 0.2664233576642336\n",
      "avg_width_train is 0.7206325329587214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[83], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m truth, preds, rmse_over \u001b[38;5;241m=\u001b[39m \u001b[43mrep_one\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[82], line 120\u001b[0m, in \u001b[0;36mrep_one\u001b[0;34m(idx, batch_size, var_weights, reduction, inflation_factor, R_t_small, fudge)\u001b[0m\n\u001b[1;32m    116\u001b[0m initial_ensembles_cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(initial_ensembles\u001b[38;5;241m.\u001b[39mT) \u001b[38;5;241m+\u001b[39mfudge\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39midentity(initial_ensembles\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# print(initial_ensembles_cov.shape)\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m initial_ensembles \u001b[38;5;241m=\u001b[39m \u001b[43mmvn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_ensembles_mean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_ensembles_mean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_ensembles_cov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_singular\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msize_ens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m weights_ann_1 \u001b[38;5;241m=\u001b[39m current_aug_state[:, batch_targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:(batch_targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m total_weights_1)]\n\u001b[1;32m    124\u001b[0m weights_ann_2 \u001b[38;5;241m=\u001b[39m current_aug_state[:, (batch_targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m total_weights_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m): (batch_targets\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m total_weights_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m total_weights_2 )]  \n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/scipy/stats/_multivariate.py:873\u001b[0m, in \u001b[0;36mmultivariate_normal_frozen.rvs\u001b[0;34m(self, size, random_state)\u001b[0m\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrvs\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrvs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov_object\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/scipy/stats/_multivariate.py:753\u001b[0m, in \u001b[0;36mmultivariate_normal_gen.rvs\u001b[0;34m(self, mean, cov, size, random_state)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(cov_object, _covariance\u001b[38;5;241m.\u001b[39mCovViaPSD):\n\u001b[1;32m    752\u001b[0m     cov \u001b[38;5;241m=\u001b[39m cov_object\u001b[38;5;241m.\u001b[39mcovariance\n\u001b[0;32m--> 753\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmultivariate_normal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    754\u001b[0m     out \u001b[38;5;241m=\u001b[39m _squeeze_output(out)\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32mmtrand.pyx:4155\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.multivariate_normal\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/.conda/envs/enkf/lib/python3.11/site-packages/numpy/linalg/linalg.py:1657\u001b[0m, in \u001b[0;36msvd\u001b[0;34m(a, full_matrices, compute_uv, hermitian)\u001b[0m\n\u001b[1;32m   1654\u001b[0m         gufunc \u001b[38;5;241m=\u001b[39m _umath_linalg\u001b[38;5;241m.\u001b[39msvd_n_s\n\u001b[1;32m   1656\u001b[0m signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD->DdD\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isComplexType(t) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md->ddd\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1657\u001b[0m u, s, vh \u001b[38;5;241m=\u001b[39m \u001b[43mgufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1658\u001b[0m u \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39mastype(result_t, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1659\u001b[0m s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mastype(_realType(result_t), copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "truth, preds, rmse_over = rep_one(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e133ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_weights_1 + 256 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234b928-6ac3-4132-b547-dff8e4dbe78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e46e452-cb5b-4ee5-b493-3ff0b8d5ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74514890-5dbd-497e-8001-546edc457b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rep_one(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enkf",
   "language": "python",
   "name": "enkf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
